'''This file will contain a few classes to facilitate the training and execution of a decision tree, in addition it will contain a way to use a pre-trained model (which may or may not be stored on an external file)''''''This is a helper class to allow the model to better understand the data it is working with, storing some usefull infoPrimaryKey should be a key in the DF used, and should be unique. It is used to signify individual tuples.allKeys is a list of all keys, this can be obtained from the DF but this spec allows the model to train on a subset of the dataframe if needed.'''import numpy as npfrom sklearn import tree'''class ModelSignifier():    def  __init__(self, primaryKey, allKeys):        if (not primaryKey in allKeys):           raise ValueError("Primary key missing from allKeys ")               self.primaryKey = primaryKey        self.allKeys = [primaryKey] + allKeys.remove(primaryKey)''''''Decision Tree class is a wrapper for the sklearn DecisionTreeClassifier() classConstructor takes a tuple of (Training Data, corresponding expected output). Training data is a 2d array of scalars (ints or floats), expected output is a 1d array of int statesie 1 could be reutrned, 0 could be not returned'''class DecisionTree():    def __init__(self, TrainingTuple, testTuple=None):        #first the training        self.model = tree.DecisionTreeClassifier()        self.model = self.model.fit(TrainingTuple[0], TrainingTuple[1])        #then testing if applicable        if (testTuple==None):            return        print("Accuracy Fraction = " + str(self.testModel(testTuple[0], testTuple[1])[0]))    '''     The model takes some test data and some expected output and compares them. Parameters are of the form of a 2d array of scalars, and a 1d array of    integer classification results that are "expected"        '''    def testModel(self, testInputs, expected):        total = len(testInputs)        count = 0        TupOut = self.Predict(testInputs)        for index in range(total):            if (TupOut[index] == expected[index]):                count += 1        return (count/total, count, total)    '''    Very simple method that exists because I may want to modify attributes of how predictions are called in the future    '''    def Predict(self, data):        return self.model.predict(data)    '''    Also simple method which allows access to a visualization of the graph,     simplifies aspects of calling this method    '''    def plot(self):        tree.plot_tree(self.model)        '''    Planned functionality to train a new model in place quickly to allow efficient configuration                def TrainNewModel(self, data):        #todo:implement        pass    ''''''(Test code)x = [[0,0], [1,1]]y = [0,1]t1 = (x,y)t2 = ([[.1,.1],[.9,.9], [.3,.3]], [0,1,1])tW = DecisionTree(t1, testTuple=t2)'''